{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "19yIa_9TcmecPBVlEiTtGOU5WMP00rtif",
      "authorship_tag": "ABX9TyN2XzjuilSwZ80njXseOQaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veer8023/veer3333/blob/main/efficeintnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vagg3HR30-ic"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPw7upNRFmbw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3nECqfjiVJvy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import random\n",
        "import cv2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow import keras\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard ,LearningRateScheduler\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam, Adamax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "TARGET_SIZE = (224, 224)\n",
        "# Walk through each directory\n",
        "dataset = \"/content/drive/MyDrive/DriveApp (2)/CUB_200_2011/images\""
      ],
      "metadata": {
        "id": "RXkIoLq_WFxW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = Path(dataset)\n",
        "\n",
        "# Get filepaths and labels\n",
        "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))\n",
        "\n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenate filepaths and labels\n",
        "image_df = pd.concat([filepaths, labels], axis=1)\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG8VLPaVVX54",
        "outputId": "9b5e1d20-6e51-4dbd-a35b-8421c6b0b4c7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            003.Sooty_Albatross\n",
              "1            003.Sooty_Albatross\n",
              "2            003.Sooty_Albatross\n",
              "3            003.Sooty_Albatross\n",
              "4            003.Sooty_Albatross\n",
              "                  ...           \n",
              "11793    200.Common_Yellowthroat\n",
              "11794    200.Common_Yellowthroat\n",
              "11795    200.Common_Yellowthroat\n",
              "11796    200.Common_Yellowthroat\n",
              "11797    200.Common_Yellowthroat\n",
              "Name: Label, Length: 11798, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ela_cv(path, quality):\n",
        "    temp_filename = 'temp_file_name.jpeg'\n",
        "    SCALE = 15\n",
        "    orig_img = cv2.imread(path)\n",
        "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
        "\n",
        "    # read compressed image\n",
        "    compressed_img = cv2.imread(temp_filename)\n",
        "\n",
        "    # get absolute difference between img1 and img2 and multiply by scale\n",
        "    diff = SCALE * cv2.absdiff(orig_img, compressed_img)\n",
        "    return diff\n",
        "\n",
        "\n",
        "def convert_to_ela_image(path, quality):\n",
        "    temp_filename = 'temp_file_name.jpeg'\n",
        "    ela_filename = 'temp_ela.png'\n",
        "    image = Image.open(path).convert('RGB')\n",
        "    image.save(temp_filename, 'JPEG', quality = quality)\n",
        "    temp_image = Image.open(temp_filename)\n",
        "\n",
        "    ela_image = ImageChops.difference(image, temp_image)\n",
        "\n",
        "    extrema = ela_image.getextrema()\n",
        "    max_diff = max([ex[1] for ex in extrema])\n",
        "    if max_diff == 0:\n",
        "        max_diff = 1\n",
        "\n",
        "    scale = 255.0 / max_diff\n",
        "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
        "\n",
        "    return ela_image\n",
        "\n",
        "\n",
        "def random_sample(path, extension=None):\n",
        "    if extension:\n",
        "        items = Path(path).glob(f'*.{extension}')\n",
        "    else:\n",
        "        items = Path(path).glob(f'*')\n",
        "\n",
        "    items = list(items)\n",
        "\n",
        "    p = random.choice(items)\n",
        "    return p.as_posix()\n",
        "\n"
      ],
      "metadata": {
        "id": "78uZPxO8VZwx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate in train and test data\n",
        "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n",
        "train_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
        ")\n",
        "# Split the data into three categories.\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=TARGET_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBw2l72IWwgs",
        "outputId": "81a8eadc-0770-485d-9a55-c8c77cd8e697"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7551 validated image filenames belonging to 200 classes.\n",
            "Found 1887 validated image filenames belonging to 200 classes.\n",
            "Found 2360 validated image filenames belonging to 200 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (224, 224,3)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_images.class_indices.keys()))  # to define the number of classes in the dense layer\n",
        "\n",
        "# create pre-trained model\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n",
        "    Dense(1024, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
        "\n",
        "    Dense(512, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
        "    Dropout(rate=0.3, seed=123),\n",
        "    Dense(class_count, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.load_weights('./checkpoints/my_checkpoint')\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYSW6XiUX6R9",
        "outputId": "e56046e8-9ad7-42f7-8618-5bbe24b703a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 1536)             6144      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1024)              1573888   \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 200)               102600    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,990,967\n",
            "Trainable params: 12,900,592\n",
            "Non-trainable params: 90,375\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, model, base_model, patience, stop_patience, threshold, factor, batches, initial_epoch, epochs, ask_epoch):\n",
        "        super(MyCallback, self).__init__()\n",
        "        self.model = model\n",
        "        self.base_model = base_model\n",
        "        self.patience = patience # specifies how many epochs without improvement before learning rate is adjusted\n",
        "        self.stop_patience = stop_patience # specifies how many times to adjust lr without improvement to stop training\n",
        "        self.threshold = threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n",
        "        self.factor = factor # factor by which to reduce the learning rate\n",
        "        self.batches = batches # number of training batch to runn per epoch\n",
        "        self.initial_epoch = initial_epoch\n",
        "        self.epochs = epochs\n",
        "        self.ask_epoch = ask_epoch\n",
        "        self.ask_epoch_initial = ask_epoch # save this value to restore if restarting training\n",
        "        # callback variables\n",
        "        self.count = 0 # how many times lr has been reduced without improvement\n",
        "        self.stop_count = 0\n",
        "        self.best_epoch = 1   # epoch with the lowest loss\n",
        "        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initial learning rate and save it\n",
        "        self.highest_tracc = 0.0 # set highest training accuracy to 0 initially\n",
        "        self.lowest_vloss = np.inf # set lowest validation loss to infinity initially\n",
        "        self.best_weights = self.model.get_weights() # set best weights to model's initial weights\n",
        "        self.initial_weights = self.model.get_weights()   # save initial weights if they have to get restored\n",
        "\n",
        "    # Define a function that will run when train begins\n",
        "    def on_train_begin(self, logs= None):\n",
        "        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n",
        "        print(msg)\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_train_end(self, logs= None):\n",
        "        stop_time = time.time()\n",
        "        tr_duration = stop_time - self.start_time\n",
        "        hours = tr_duration // 3600\n",
        "        minutes = (tr_duration - (hours * 3600)) // 60\n",
        "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
        "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
        "        print(msg)\n",
        "        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs= None):\n",
        "        acc = logs.get('accuracy') * 100 # get batch accuracy\n",
        "        loss = logs.get('loss')\n",
        "        msg = '{0:20s}processing batch {1:} of {2:5s}-   accuracy=  {3:5.3f}   -   loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n",
        "        print(msg, '\\r', end= '') # prints over on the same line to show running batch count\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs= None):\n",
        "        self.ep_start = time.time()\n",
        "\n",
        "    # Define method runs on the end of each epoch\n",
        "    def on_epoch_end(self, epoch, logs= None):\n",
        "        ep_end = time.time()\n",
        "        duration = ep_end - self.ep_start\n",
        "\n",
        "        lr = float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
        "        current_lr = lr\n",
        "        acc = logs.get('accuracy')  # get training accuracy\n",
        "        v_acc = logs.get('val_accuracy')  # get validation accuracy\n",
        "        loss = logs.get('loss')  # get training loss for this epoch\n",
        "        v_loss = logs.get('val_loss')  # get the validation loss for this epoch\n",
        "\n",
        "        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n",
        "            monitor = 'accuracy'\n",
        "            if epoch == 0:\n",
        "                pimprov = 0.0\n",
        "            else:\n",
        "                pimprov = (acc - self.highest_tracc ) * 100 / self.highest_tracc # define improvement of model progres\n",
        "\n",
        "            if acc > self.highest_tracc: # training accuracy improved in the epoch\n",
        "                self.highest_tracc = acc # set new highest training accuracy\n",
        "                self.best_weights = self.model.get_weights() # training accuracy improved so save the weights\n",
        "                self.count = 0 # set count to 0 since training accuracy improved\n",
        "                self.stop_count = 0 # set stop counter to 0\n",
        "                if v_loss < self.lowest_vloss:\n",
        "                    self.lowest_vloss = v_loss\n",
        "                self.best_epoch = epoch + 1  # set the value of best epoch for this epoch\n",
        "\n",
        "            else:\n",
        "                # training accuracy did not improve check if this has happened for patience number of epochs\n",
        "                # if so adjust learning rate\n",
        "                if self.count >= self.patience - 1: # lr should be adjusted\n",
        "                    lr = lr * self.factor # adjust the learning by factor\n",
        "                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n",
        "                    self.count = 0 # reset the count to 0\n",
        "                    self.stop_count = self.stop_count + 1 # count the number of consecutive lr adjustments\n",
        "                    self.count = 0 # reset counter\n",
        "                    if v_loss < self.lowest_vloss:\n",
        "                        self.lowest_vloss = v_loss\n",
        "                else:\n",
        "                    self.count = self.count + 1 # increment patience counter\n",
        "\n",
        "        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n",
        "            monitor = 'val_loss'\n",
        "            if epoch == 0:\n",
        "                pimprov = 0.0\n",
        "            else:\n",
        "                pimprov = (self.lowest_vloss - v_loss ) * 100 / self.lowest_vloss\n",
        "            if v_loss < self.lowest_vloss: # check if the validation loss improved\n",
        "                self.lowest_vloss = v_loss # replace lowest validation loss with new validation loss\n",
        "                self.best_weights = self.model.get_weights() # validation loss improved so save the weights\n",
        "                self.count = 0 # reset count since validation loss improved\n",
        "                self.stop_count = 0\n",
        "                self.best_epoch = epoch + 1 # set the value of the best epoch to this epoch\n",
        "            else: # validation loss did not improve\n",
        "                if self.count >= self.patience - 1: # need to adjust lr\n",
        "                    lr = lr * self.factor # adjust the learning rate\n",
        "                    self.stop_count = self.stop_count + 1 # increment stop counter because lr was adjusted\n",
        "                    self.count = 0 # reset counter\n",
        "                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n",
        "                else:\n",
        "                    self.count = self.count + 1 # increment the patience counter\n",
        "                if acc > self.highest_tracc:\n",
        "                    self.highest_tracc = acc\n",
        "\n",
        "        msg = f'{str(epoch + 1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc * 100:^9.3f}{v_loss:^9.5f}{v_acc * 100:^9.3f}{current_lr:^9.5f}{lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n",
        "        print(msg)\n",
        "\n",
        "        if self.stop_count > self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n",
        "            msg = f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n",
        "            print(msg)\n",
        "            self.model.stop_training = True # stop training\n",
        "\n",
        "        else:\n",
        "            if self.ask_epoch != None:\n",
        "                if epoch + 1 >= self.ask_epoch:\n",
        "                    msg = 'enter H to halt training or an integer for number of epochs to run then ask again'\n",
        "                    print(msg)\n",
        "                    ans = input('')\n",
        "                    if ans == 'H' or ans == 'h':\n",
        "                        msg = f'training has been halted at epoch {epoch + 1} due to user input'\n",
        "                        print(msg)\n",
        "                        self.model.stop_training = True # stop training\n",
        "                    else:\n",
        "                        try:\n",
        "                            ans = int(ans)\n",
        "                            self.ask_epoch += ans\n",
        "                            msg = f' training will continue until epoch ' + str(self.ask_epoch)\n",
        "                            print(msg)\n",
        "                            msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor', '% Improv', 'Duration')\n",
        "                            print(msg)\n",
        "                        except:\n",
        "                            print('Invalid')"
      ],
      "metadata": {
        "id": "CscTGHfSYgpr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 40\n",
        "epochs = 50\n",
        "patience = 1\n",
        "stop_patience = 3\n",
        "threshold = 0.9\n",
        "factor = 0.5\n",
        "freeze = False\n",
        "ask_epoch = 1\n",
        "batches = int(np.ceil(len(train_images.labels) / batch_size))\n",
        "\n",
        "\n",
        "callbacks = [MyCallback(model= model, base_model= base_model, patience= patience,\n",
        "            stop_patience= stop_patience, threshold= threshold, factor= factor,\n",
        "            batches= batches, initial_epoch= 0, epochs= epochs, ask_epoch= ask_epoch )]"
      ],
      "metadata": {
        "id": "DVRnpO1y0hZ_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x= train_images, epochs= epochs, verbose= 0, callbacks= callbacks,\n",
        "                    validation_data= val_images, validation_steps= None, shuffle= True,\n",
        "                    initial_epoch= 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vToZCV3z0uTQ",
        "outputId": "a352a269-f228-41e5-d0cf-16700f62d8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n",
            " 1 /50    10.451   13.336   7.57511  39.799   0.00100  0.00100  accuracy     0.00   2045.76 \n",
            "enter H to halt training or an integer for number of epochs to run then ask again\n",
            "5\n",
            " training will continue until epoch 6\n",
            " Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n",
            " 2 /50     6.300   48.285   5.03926  58.824   0.00100  0.00100  accuracy    262.07   127.55 \n",
            " 3 /50     4.173   68.892   3.69189  68.045   0.00100  0.00100  accuracy    42.68    129.43 \n",
            " 4 /50     2.924   81.340   2.95901  70.747   0.00100  0.00100  accuracy    18.07    128.27 \n",
            " 5 /50     2.192   88.425   2.50362  71.807   0.00100  0.00100  accuracy     8.71    127.64 \n",
            " 6 /50     1.731   93.259   2.27147  71.701   0.00100  0.00100  val_loss     9.27    127.77 \n",
            "enter H to halt training or an integer for number of epochs to run then ask again\n",
            "H\n",
            "training has been halted at epoch 6 due to user input\n",
            "training elapsed time was 0.0 hours, 45.0 minutes, 54.58 seconds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n",
        "        layer.trainable = False\n",
        "\n",
        "# let`s see first 10 layers\n",
        "for l in base_model.layers[:10]:\n",
        "    print(l.name, l.trainable)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "#model.load_weights('./checkpoints/my_checkpoint')\n",
        "print(model.summary())\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
        "                               patience = 5,\n",
        "                               restore_best_weights = True), # if val loss decreases for 5 epochs in a row, stop training,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n",
        "    ]\n",
        ")\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "img_size = (224, 224,3)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_images.class_indices.keys()))  # to define the number of classes in the dense layer\n",
        "\n",
        "# create pre-trained model\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n",
        "    Dense(1024, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
        "    Dense(512, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
        "    Dropout(rate=0.35, seed=123),\n",
        "\n",
        "    Dense(class_count, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "model.summary()\n",
        "\n",
        "batch_size = 40\n",
        "epochs = 20\n",
        "patience = 1\n",
        "stop_patience = 3\n",
        "threshold = 0.9\n",
        "factor = 0.5\n",
        "freeze = False\n",
        "ask_epoch = 5\n",
        "batches = int(np.ceil(len(train_images.labels) / batch_size))\n",
        "\n",
        "\n",
        "callbacks = [MyCallback(model= model, base_model= base_model, patience= patience,\n",
        "            stop_patience= stop_patience, threshold= threshold, factor= factor,\n",
        "            batches= batches, initial_epoch= 0, epochs= epochs, ask_epoch= ask_epoch )]\n",
        "\n",
        "history = model.fit(x= train_images, epochs= epochs, verbose= 0, callbacks= callbacks,\n",
        "                    validation_data= val_images, validation_steps= None, shuffle= True,\n",
        "                    initial_epoch= 0)"
      ],
      "metadata": {
        "id": "Os7jSCWVFBN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda45f27-5445-447f-efd9-09b17358428f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 True\n",
            "rescaling True\n",
            "normalization True\n",
            "rescaling_1 True\n",
            "stem_conv_pad True\n",
            "stem_conv True\n",
            "stem_bn False\n",
            "stem_activation True\n",
            "block1a_dwconv True\n",
            "block1a_bn False\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 1536)             6144      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               393472    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               51400     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,234,551\n",
            "Trainable params: 11,056,880\n",
            "Non-trainable params: 177,671\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "236/236 [==============================] - 162s 478ms/step - loss: 1.3950 - accuracy: 0.9837 - val_loss: 2.1388 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "236/236 [==============================] - 108s 458ms/step - loss: 1.3329 - accuracy: 0.9887 - val_loss: 2.0937 - val_accuracy: 0.7621 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "236/236 [==============================] - 108s 458ms/step - loss: 1.2860 - accuracy: 0.9918 - val_loss: 2.0622 - val_accuracy: 0.7615 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "236/236 [==============================] - 109s 463ms/step - loss: 1.2527 - accuracy: 0.9928 - val_loss: 2.0291 - val_accuracy: 0.7631 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "236/236 [==============================] - 108s 458ms/step - loss: 1.2177 - accuracy: 0.9960 - val_loss: 2.0022 - val_accuracy: 0.7658 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "236/236 [==============================] - 108s 458ms/step - loss: 1.1852 - accuracy: 0.9959 - val_loss: 1.9792 - val_accuracy: 0.7647 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "236/236 [==============================] - 109s 463ms/step - loss: 1.1536 - accuracy: 0.9967 - val_loss: 1.9514 - val_accuracy: 0.7647 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "236/236 [==============================] - 109s 462ms/step - loss: 1.1349 - accuracy: 0.9980 - val_loss: 1.9255 - val_accuracy: 0.7721 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "236/236 [==============================] - 108s 458ms/step - loss: 1.1081 - accuracy: 0.9970 - val_loss: 1.9125 - val_accuracy: 0.7668 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "236/236 [==============================] - 108s 459ms/step - loss: 1.0833 - accuracy: 0.9984 - val_loss: 1.8940 - val_accuracy: 0.7721 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "236/236 [==============================] - 109s 461ms/step - loss: 1.0596 - accuracy: 0.9989 - val_loss: 1.8692 - val_accuracy: 0.7700 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "236/236 [==============================] - 109s 460ms/step - loss: 1.0422 - accuracy: 0.9980 - val_loss: 1.8524 - val_accuracy: 0.7652 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "236/236 [==============================] - 109s 463ms/step - loss: 1.0197 - accuracy: 0.9989 - val_loss: 1.8378 - val_accuracy: 0.7695 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "236/236 [==============================] - 109s 462ms/step - loss: 1.0018 - accuracy: 0.9981 - val_loss: 1.8255 - val_accuracy: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "236/236 [==============================] - 109s 463ms/step - loss: 0.9837 - accuracy: 0.9992 - val_loss: 1.8088 - val_accuracy: 0.7674 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "236/236 [==============================] - 109s 462ms/step - loss: 0.9636 - accuracy: 0.9991 - val_loss: 1.7934 - val_accuracy: 0.7705 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "236/236 [==============================] - 108s 459ms/step - loss: 0.9477 - accuracy: 0.9991 - val_loss: 1.7810 - val_accuracy: 0.7684 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "236/236 [==============================] - 109s 462ms/step - loss: 0.9336 - accuracy: 0.9984 - val_loss: 1.7696 - val_accuracy: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "236/236 [==============================] - 109s 460ms/step - loss: 0.9173 - accuracy: 0.9999 - val_loss: 1.7531 - val_accuracy: 0.7716 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "236/236 [==============================] - 108s 458ms/step - loss: 0.9037 - accuracy: 0.9993 - val_loss: 1.7408 - val_accuracy: 0.7689 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "236/236 [==============================] - 109s 462ms/step - loss: 0.8913 - accuracy: 0.9995 - val_loss: 1.7262 - val_accuracy: 0.7716 - lr: 1.0000e-05\n",
            "Epoch 22/30\n",
            "236/236 [==============================] - 108s 459ms/step - loss: 0.8766 - accuracy: 0.9996 - val_loss: 1.7134 - val_accuracy: 0.7716 - lr: 1.0000e-05\n",
            "Epoch 23/30\n",
            "236/236 [==============================] - 109s 460ms/step - loss: 0.8622 - accuracy: 0.9993 - val_loss: 1.7048 - val_accuracy: 0.7711 - lr: 1.0000e-05\n",
            "Epoch 24/30\n",
            "236/236 [==============================] - 109s 460ms/step - loss: 0.8500 - accuracy: 0.9999 - val_loss: 1.6978 - val_accuracy: 0.7721 - lr: 1.0000e-05\n",
            "Epoch 25/30\n",
            "236/236 [==============================] - 110s 465ms/step - loss: 0.8368 - accuracy: 0.9997 - val_loss: 1.6870 - val_accuracy: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 26/30\n",
            "236/236 [==============================] - 109s 462ms/step - loss: 0.8258 - accuracy: 0.9997 - val_loss: 1.6718 - val_accuracy: 0.7748 - lr: 1.0000e-05\n",
            "Epoch 27/30\n",
            "236/236 [==============================] - 110s 464ms/step - loss: 0.8147 - accuracy: 0.9997 - val_loss: 1.6616 - val_accuracy: 0.7737 - lr: 1.0000e-05\n",
            "Epoch 28/30\n",
            "236/236 [==============================] - 110s 466ms/step - loss: 0.7995 - accuracy: 0.9999 - val_loss: 1.6533 - val_accuracy: 0.7711 - lr: 1.0000e-05\n",
            "Epoch 29/30\n",
            "236/236 [==============================] - 109s 463ms/step - loss: 0.7931 - accuracy: 0.9997 - val_loss: 1.6429 - val_accuracy: 0.7753 - lr: 1.0000e-05\n",
            "Epoch 30/30\n",
            "236/236 [==============================] - 110s 467ms/step - loss: 0.7789 - accuracy: 0.9996 - val_loss: 1.6322 - val_accuracy: 0.7769 - lr: 1.0000e-05\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1536)             6144      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               393472    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 200)               51400     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,234,551\n",
            "Trainable params: 11,144,176\n",
            "Non-trainable params: 90,375\n",
            "_________________________________________________________________\n",
            " Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n",
            " 1 /50     0.857   99.775   1.62726  77.477   0.00001  0.00001  val_loss     0.00    195.98 \n",
            " 2 /50     0.857   99.735   1.62643  77.477   0.00001  0.00001  val_loss     0.05    127.98 \n",
            " 3 /50     0.845   99.748   1.62508  77.583   0.00001  0.00001  val_loss     0.08    127.81 \n",
            " 4 /50     0.842   99.762   1.62378  77.636   0.00001  0.00001  val_loss     0.08    127.72 \n",
            " 5 /50     0.843   99.762   1.62215  77.636   0.00001  0.00001  val_loss     0.10    128.56 \n",
            " 6 /50     0.834   99.788   1.62092  77.583   0.00001  0.00001  val_loss     0.08    128.72 \n",
            " 7 /50     0.834   99.828   1.62049  77.689   0.00001  0.00001  val_loss     0.03    127.86 \n",
            " 8 /50     0.833   99.762   1.61996  77.318   0.00001  0.00001  val_loss     0.03    128.52 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n",
        "        layer.trainable = False\n",
        "\n",
        "# let`s see first 10 layers\n",
        "for l in base_model.layers[:10]:\n",
        "    print(l.name, l.trainable)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "#model.load_weights('./checkpoints/my_checkpoint')\n",
        "print(model.summary())\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
        "                               patience = 5,\n",
        "                               restore_best_weights = True), # if val loss decreases for 5 epochs in a row, stop training,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n",
        "    ]\n",
        ")\n",
        "model.save_weights('/content/drive/MyDrive/DeepLearningModels/e3weight.h5')\n",
        "img_size = (224, 224,3)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_images.class_indices.keys()))  # to define the number of classes in the dense layer\n",
        "\n",
        "# create pre-trained model\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n",
        "    Dense(1024, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
        "    Dense(512, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
        "    Dropout(rate=0.35, seed=123),\n",
        "\n",
        "    Dense(class_count, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.load_weights('./checkpoints/my_checkpoint')\n",
        "model.summary()\n",
        "\n",
        "batch_size = 40\n",
        "epochs = 20\n",
        "patience = 1\n",
        "stop_patience = 3\n",
        "threshold = 0.9\n",
        "factor = 0.5\n",
        "freeze = False\n",
        "ask_epoch = 5\n",
        "batches = int(np.ceil(len(train_images.labels) / batch_size))\n",
        "\n",
        "\n",
        "callbacks = [MyCallback(model= model, base_model= base_model, patience= patience,\n",
        "            stop_patience= stop_patience, threshold= threshold, factor= factor,\n",
        "            batches= batches, initial_epoch= 0, epochs= epochs, ask_epoch= ask_epoch )]\n",
        "\n",
        "history = model.fit(x= train_images, epochs= epochs, verbose= 0, callbacks= callbacks,\n",
        "                    validation_data= val_images, validation_steps= None, shuffle= True,\n",
        "                    initial_epoch= 0)"
      ],
      "metadata": {
        "id": "XWuubLYN9ZV-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2e5743d-ea26-40a9-fb83-f8f81ffeac7d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_8 True\n",
            "rescaling_14 True\n",
            "normalization_7 True\n",
            "rescaling_15 True\n",
            "stem_conv_pad True\n",
            "stem_conv True\n",
            "stem_bn False\n",
            "stem_activation True\n",
            "block1a_dwconv True\n",
            "block1a_bn False\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 1536)             6144      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1024)              1573888   \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 200)               102600    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,990,967\n",
            "Trainable params: 12,813,296\n",
            "Non-trainable params: 177,671\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "236/236 [==============================] - 158s 470ms/step - loss: 9.5222 - accuracy: 0.0073 - val_loss: 8.9596 - val_accuracy: 0.0026 - lr: 1.0000e-05\n",
            "Epoch 2/20\n",
            "236/236 [==============================] - 109s 463ms/step - loss: 8.4870 - accuracy: 0.0061 - val_loss: 8.0525 - val_accuracy: 0.0016 - lr: 1.0000e-05\n",
            "Epoch 3/20\n",
            "236/236 [==============================] - 109s 459ms/step - loss: 7.6938 - accuracy: 0.0062 - val_loss: 7.3654 - val_accuracy: 0.0026 - lr: 1.0000e-05\n",
            "Epoch 4/20\n",
            "236/236 [==============================] - 109s 462ms/step - loss: 7.0934 - accuracy: 0.0062 - val_loss: 6.8448 - val_accuracy: 0.0026 - lr: 1.0000e-05\n",
            "Epoch 5/20\n",
            "236/236 [==============================] - 109s 462ms/step - loss: 6.6398 - accuracy: 0.0062 - val_loss: 6.4529 - val_accuracy: 0.0026 - lr: 1.0000e-05\n",
            "Epoch 6/20\n",
            "236/236 [==============================] - 109s 461ms/step - loss: 6.2975 - accuracy: 0.0062 - val_loss: 6.1566 - val_accuracy: 0.0026 - lr: 1.0000e-05\n",
            "Epoch 7/20\n",
            "236/236 [==============================] - 109s 461ms/step - loss: 6.0394 - accuracy: 0.0062 - val_loss: 5.9335 - val_accuracy: 0.0026 - lr: 1.0000e-05\n",
            "Epoch 8/20\n",
            "236/236 [==============================] - 109s 461ms/step - loss: 5.8448 - accuracy: 0.0062 - val_loss: 5.7654 - val_accuracy: 0.0026 - lr: 1.0000e-05\n",
            "Epoch 9/20\n",
            "121/236 [==============>...............] - ETA: 48s - loss: 5.7296 - accuracy: 0.0057"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5d9df62dc07f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#model.load_weights('./checkpoints/my_checkpoint')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/DeepLearningModels/e3weight.h5')"
      ],
      "metadata": {
        "id": "ezcdA1VZphLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x= train_images, epochs= epochs, verbose= 0, callbacks= callbacks,\n",
        "                    validation_data= val_images, validation_steps= None, shuffle= True,\n",
        "                    initial_epoch= 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OkCIu5C-rmTq",
        "outputId": "ad933305-b9b9-4cc7-fefe-be614e15fef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n",
            " 1 /50    15.975   22.752  14.86741  46.052   0.00001  0.00001  accuracy     0.00    246.54 \n",
            " 2 /50    15.579   27.970  15.00817  43.084   0.00001  0.00001  accuracy    22.93    126.17 \n",
            " 3 /50    15.249   33.241  14.77019  45.840   0.00001  0.00001  accuracy    18.84    126.08 \n",
            " 4 /50    14.938   37.465  14.52063  47.854   0.00001  0.00001  accuracy    12.71    126.52 \n",
            " 5 /50    14.658   42.008  14.28663  50.503   0.00001  0.00001  accuracy    12.12    126.82 \n",
            " 6 /50    14.379   46.749  14.05863  52.835   0.00001  0.00001  accuracy    11.29    126.18 \n",
            " 7 /50    14.158   48.735  13.84857  55.485   0.00001  0.00001  accuracy     4.25    126.57 \n",
            " 8 /50    13.920   51.834  13.64486  57.340   0.00001  0.00001  accuracy     6.36    126.71 \n",
            " 9 /50    13.713   55.079  13.46105  58.612   0.00001  0.00001  accuracy     6.26    126.51 \n",
            "10 /50    13.483   57.860  13.28799  59.565   0.00001  0.00001  accuracy     5.05    126.44 \n",
            "11 /50    13.301   59.330  13.11195  60.413   0.00001  0.00001  accuracy     2.54    126.37 \n",
            "12 /50    13.096   62.164  12.95624  61.420   0.00001  0.00001  accuracy     4.78    125.93 \n",
            "13 /50    12.932   63.157  12.80189  62.162   0.00001  0.00001  accuracy     1.60    127.10 \n",
            "14 /50    12.750   64.932  12.65633  63.540   0.00001  0.00001  accuracy     2.81    126.61 \n",
            "15 /50    12.605   65.885  12.51514  64.335   0.00001  0.00001  accuracy     1.47    126.91 \n",
            "16 /50    12.459   67.475  12.37725  64.759   0.00001  0.00001  accuracy     2.41    126.18 \n",
            "17 /50    12.306   68.507  12.24591  65.872   0.00001  0.00001  accuracy     1.53    126.69 \n",
            "18 /50    12.168   69.580  12.11579  66.243   0.00001  0.00001  accuracy     1.57    125.62 \n",
            "19 /50    12.032   70.481  11.99317  66.720   0.00001  0.00001  accuracy     1.29    127.05 \n",
            "20 /50    11.894   71.408  11.87332  67.462   0.00001  0.00001  accuracy     1.32    126.58 \n",
            "21 /50    11.750   72.375  11.75434  67.939   0.00001  0.00001  accuracy     1.35    126.75 \n",
            "22 /50    11.629   72.917  11.63941  68.309   0.00001  0.00001  accuracy     0.75    125.70 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a272b264b574>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(x= train_images, epochs= epochs, verbose= 0, callbacks= callbacks,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     initial_epoch= 0)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/images/101.White_Pelican/White_Pelican_0050_97913.jpg'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/images/101.White_Pelican/White_Pelican_0050_97913.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/images/101.White_Pelican/White_Pelican_0050_97913.jpg'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\", line 1049, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/images/101.White_Pelican/White_Pelican_0050_97913.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_387111]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x= train_images, epochs= epochs, verbose= 0, callbacks= callbacks,\n",
        "                    validation_data= val_images, validation_steps= None, shuffle= True,\n",
        "                    initial_epoch= 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ldzRVMBDoV0",
        "outputId": "d403cd21-af69-45d8-c642-0b411ff97a01"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\n",
            " 1 /50    19.811    0.742  10.18629   0.848   0.00100  0.00100  accuracy     0.00    194.83 \n",
            " 2 /50     7.525    0.649   6.06539   0.265   0.00100  0.00050  accuracy    -12.50   128.61 \n",
            " 3 /50     5.790    0.596   5.58617   0.265   0.00050  0.00025  accuracy    -19.64   127.52 \n",
            " 4 /50     5.519    0.622   5.46301   0.265   0.00025  0.00013  accuracy    -16.07   128.38 \n",
            " training has been halted at epoch 4 after 3 adjustments of learning rate with no improvement\n",
            "training elapsed time was 0.0 hours, 10.0 minutes, 31.26 seconds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n",
        "        layer.trainable = False\n",
        "\n",
        "# let`s see first 10 layers\n",
        "for l in base_model.layers[:10]:\n",
        "    print(l.name, l.trainable)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "#model.load_weights('./checkpoints/my_checkpoint')\n",
        "print(model.summary())\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=30,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
        "                               patience = 5,\n",
        "                               restore_best_weights = True), # if val loss decreases for 5 epochs in a row, stop training,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n",
        "    ]\n",
        ")\n",
        "model.save_weights('/content/drive/MyDrive/DeepLearningModels/e3weight.h5')\n",
        "img_size = (224, 224,3)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_images.class_indices.keys()))  # to define the number of classes in the dense layer\n",
        "\n",
        "# create pre-trained model\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n",
        "    Dense(1024, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
        "    Dense(512, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
        "    Dropout(rate=0.35, seed=123),\n",
        "\n",
        "    Dense(class_count, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "model.summary()\n",
        "\n",
        "batch_size = 40\n",
        "epochs = 50\n",
        "patience = 1\n",
        "stop_patience = 3\n",
        "threshold = 0.9\n",
        "factor = 0.5\n",
        "freeze = False\n",
        "ask_epoch = 20\n",
        "batches = int(np.ceil(len(train_images.labels) / batch_size))\n",
        "\n",
        "\n",
        "callbacks = [MyCallback(model= model, base_model= base_model, patience= patience,\n",
        "            stop_patience= stop_patience, threshold= threshold, factor= factor,\n",
        "            batches= batches, initial_epoch= 0, epochs= epochs, ask_epoch= ask_epoch )]\n",
        "\n",
        "history = model.fit(x= train_images, epochs= epochs, verbose= 0, callbacks= callbacks,\n",
        "                    validation_data= val_images, validation_steps= None, shuffle= True,\n",
        "                    initial_epoch= 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "03smSFcynfmo",
        "outputId": "bf7dab60-234a-449d-c13f-b457cf57ec73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_5 True\n",
            "rescaling_8 True\n",
            "normalization_4 True\n",
            "rescaling_9 True\n",
            "stem_conv_pad True\n",
            "stem_conv True\n",
            "stem_bn False\n",
            "stem_activation True\n",
            "block1a_dwconv True\n",
            "block1a_bn False\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 1536)             6144      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 2048)              3147776   \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 2048)              4196352   \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 200)               409800    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,543,607\n",
            "Trainable params: 18,365,936\n",
            "Non-trainable params: 177,671\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "236/236 [==============================] - 160s 473ms/step - loss: 8.0916 - accuracy: 0.0058 - val_loss: 7.4635 - val_accuracy: 0.0037 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "236/236 [==============================] - 109s 461ms/step - loss: 7.0220 - accuracy: 0.0062 - val_loss: 6.6389 - val_accuracy: 0.0037 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "236/236 [==============================] - 109s 461ms/step - loss: 6.3649 - accuracy: 0.0064 - val_loss: 6.1287 - val_accuracy: 0.0037 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "236/236 [==============================] - 109s 460ms/step - loss: 5.9576 - accuracy: 0.0062 - val_loss: 5.8094 - val_accuracy: 0.0037 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "217/236 [==========================>...] - ETA: 7s - loss: 5.7090 - accuracy: 0.0066"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cb4c1775954e>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#model.load_weights('./checkpoints/my_checkpoint')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from kerastuner import HyperModel, RandomSearch, Objective\n",
        "\n",
        "# Define your bird species classification dataset and preprocessing here.\n",
        "# Replace `train_data`, `val_data`, `num_classes`, and other data-related variables accordingly.\n",
        "\n",
        "# Define the HyperModel for EfficientNetB3\n",
        "class EfficientNetB3HyperModel(HyperModel):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        self.input_shape = img_size\n",
        "        self.num_classes = class_count\n",
        "\n",
        "    def build(self, hp):\n",
        "        base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
        "\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        model = tf.keras.Sequential()\n",
        "\n",
        "        model.add(base_model)\n",
        "        model.add(layers.GlobalAveragePooling2D())\n",
        "        model.add(layers.Dense(units=hp.Int('dense_units', min_value=128, max_value=512, step=32), activation='relu'))\n",
        "        model.add(layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "        model.add(layers.Dense(units=hp.Int('dense_units', min_value=128, max_value=512, step=32), activation='relu'))\n",
        "        model.add(layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "        model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "        return model\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "hypermodel = EfficientNetB3HyperModel(input_shape=(224, 224, 3), num_classes=class_count)\n",
        "\n",
        "# Define the objective function\n",
        "objective = Objective('val_accuracy', direction='max')\n",
        "\n",
        "# Initialize the RandomSearch tuner\n",
        "tuner = RandomSearch(\n",
        "    hypermodel,\n",
        "    objective=objective,\n",
        "    seed=42,\n",
        "    max_trials=10,\n",
        "    directory='my_dir',\n",
        "    project_name='bird_species_classification'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "tuner.search(train_images, epochs=10, validation_data=val_images)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=10)[0]\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hps)\n",
        "\n",
        "# Build and compile the model with the best hyperparameters\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_hps.get('learning_rate')),\n",
        "                   loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "best_model.fit(train_images, epochs=50, validation_data=val_images)\n",
        "\n"
      ],
      "metadata": {
        "id": "R56Kdt31ZhvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras-tuner\n",
        "\n",
        "!pip install scikit-optimize\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EITr8d85nRPO",
        "outputId": "0bcebb2f-7e9d-4f5b-b1bd-560b15fdee99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.1)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-23.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.7.0 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "\n",
        "# Create the EfficientNetB3 model\n",
        "def create_model(img_shape, class_count, dense_units=512, dropout_rate=0.3):\n",
        "    base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=img_shape, pooling='max')\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n",
        "        layers.Dense(units=dense_units, activation='relu'),\n",
        "        layers.Dropout(rate=dropout_rate),\n",
        "        layers.Dense(class_count, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYi_xABlnV49",
        "outputId": "a974d54f-97c0-4bbe-ad54-f5f9714dadc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1536)             6144      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               786944    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 200)               51400     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,759,351\n",
            "Trainable params: 11,668,976\n",
            "Non-trainable params: 90,375\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# Define hyperparameters for tuning\n",
        "param_grid = {\n",
        "    'epochs': [5, 10, 15],\n",
        "    'learning_rate': [0.001, 0.0001, 0.00001],\n",
        "    'kernel_regularizer': [None, l2(0.001)],  # None or L2 regularization\n",
        "    'dropout_rate': [0.0, 0.2, 0.5],  # Dropout rate for the Dense layer\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform hyperparameter search\n",
        "grid_search.fit(train_images, val_images)\n",
        "\n",
        "# Print the best hyperparameters and corresponding score\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "test_loss, test_accuracy = best_model.evaluate(train_images, val_images)\n",
        "\n",
        "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YY-LhdqInnlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rL_TQfTlnvkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "hNobHRd3sNWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QFwroWNknzA0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}